name: ci

on:
  push:

env:
  CLUSTER_NAME: ziti-agent-regression 
  AWS_REGION: us-west-2
  GKE_REGION: us-central1
  GKE_NETWORK_NAME: default
  GKE_SUBNETWORK_NAME: default

jobs:
  # docker:
  #   runs-on: ubuntu-latest
  #   steps:
  #     -
  #       name: Checkout
  #       uses: actions/checkout@v4
  #     -
  #       name: Set up QEMU
  #       uses: docker/setup-qemu-action@v3
  #     -
  #       name: Set up Docker Buildx
  #       uses: docker/setup-buildx-action@v3
  #     -
  #       name: Login to Docker Hub
  #       uses: docker/login-action@v3
  #       with:
  #         username: ${{ secrets.DOCKERHUB_USERNAME }}
  #         password: ${{ secrets.DOCKERHUB_TOKEN }}
  #     -
  #       name: Build and push
  #       uses: docker/build-push-action@v6
  #       with:
  #         context: .
  #         file: Dockerfile
  #         platforms: linux/amd64,linux/arm64
  #         push: true
  #         tags: elblag91/ziti-k8s-agent:${{ github.ref_name }}
  regression_test: 
    # needs: [docker]
    runs-on: ubuntu-latest
    permissions:
      contents: read
      id-token: write
    steps: 
      -
        name: Checkout
        uses: actions/checkout@v4
      - 
        name: Authenticate to AWS Cloud
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-region: ${{ env.AWS_REGION }}
          role-to-assume: ${{ secrets.AWS_ROLE_FOR_GITHUB }}
          role-session-name: GitHubActions
          audience: sts.amazonaws.com
      -  
        name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          workload_identity_provider: ${{ secrets.GCLOUD_WL_ID_FOR_GITHUB }}
          service_account: ${{ secrets.GCLOUD_SVC_ACCT_FOR_GITHUB }}
          audience: ${{ secrets.GCLOUD_AUD_ID_FOR_GITHUB }}
      -
        name: install-gcloud-cli
        uses: google-github-actions/setup-gcloud@v2
        with:
          version: latest
          install_components: gke-gcloud-auth-plugin
      -
        name: install-kubectl
        uses: azure/setup-kubectl@v3
        with:
          version: latest
      -
        name: install-aws-cli
        uses: unfor19/install-aws-cli-action@v1
        with:
          version: 2                         
          verbose: false                     
          arch: amd64
      - 
        name: install-postman-jq-zet-cli
        run: |
          curl -o- "https://dl-cli.pstmn.io/install/linux64.sh" | sh
          sudo apt-get update
          sudo apt-get --yes install jq 
          curl -sSLf https://get.openziti.io/tun/scripts/install-ubuntu.bash | bash
          sudo systemctl enable --now ziti-edge-tunnel.service
          curl --silent --location "https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz" | tar xz -C /tmp
          sudo mv /tmp/eksctl /usr/local/bin
      - 
        name: create-eks-cluster
        run: |
          cat <<EOF >eks-cluster.yaml
          apiVersion: eksctl.io/v1alpha5
          kind: ClusterConfig
          metadata:
            name: $CLUSTER_NAME
            region: $AWS_REGION
            version: "1.28"
          managedNodeGroups:
          - name: ng-1
            instanceType: t3.medium
            iam:
                withAddonPolicies:
                  ebs: true
                  fsx: true
                  efs: true
            desiredCapacity: 2
            privateNetworking: true
            labels:
              nodegroup-type: workloads
            tags:
              nodegroup-role: worker
          vpc:
            cidr: 10.10.0.0/16
            publicAccessCIDRs: []
            # disable public access to endpoint and only allow private access
            clusterEndpoints:
              publicAccess: true
              privateAccess: true
          EOF
          eksctl create cluster -f ./eks-cluster.yaml
          echo "AWS_CLUSTER=$(kubectl config get-contexts -o name | grep $CLUSTER_NAME | grep eksctl)" >> $GITHUB_ENV   
      -
        name: create-gke-cluster
        if: success() || failure()
        run: |
          gcloud container --project $GCP_PROJECT clusters create $CLUSTER_NAME \
          --region $GKE_REGION --no-enable-basic-auth \
          --release-channel "regular" --machine-type "e2-medium" \
          --disk-size "100" --metadata disable-legacy-endpoints=true \
          --service-account ${{ secrets.GCLOUD_SVC_ACCT_FOR_GITHUB }} \
          --network "projects/$GCP_PROJECT/global/networks/$GKE_NETWORK_NAME" \
          --subnetwork "projects/$GCP_PROJECT/regions/$GKE_REGION/subnetworks/$GKE_SUBNETWORK_NAME" \
          --no-enable-intra-node-visibility --cluster-dns=clouddns --cluster-dns-scope=cluster \
          --security-posture=standard --workload-vulnerability-scanning=disabled --no-enable-master-authorized-networks \
          --addons HorizontalPodAutoscaling,NodeLocalDNS,GcePersistentDiskCsiDriver --num-nodes "1" \
          --default-max-pods-per-node "110" --enable-ip-alias
          echo "GKE_CLUSTER=$(kubectl config get-contexts -o name | grep $CLUSTER_NAME | grep gke)" >> $GITHUB_ENV 
      -
        name: test-cluster-pods
        if: success() || failure()
        run: |
          kubectl get pods --all-namespaces --context $AWS_CLUSTER
          kubectl get pods --all-namespaces --context $GKE_CLUSTER
      -
        name: delete-clusters
        if: success() || failure()
        run: |
          eksctl delete cluster -f ./eks-cluster.yaml --force --disable-nodegroup-eviction 
          gcloud container --project $GCP_PROJECT clusters delete $CLUSTER_NAME --region $GKE_REGION --quiet
      # - name: deploy-webhook-2-clusters
      #   run: |
      #     kubectl apply -f 
      #     kubectl apply -f 

    # steps:
    # 
  
